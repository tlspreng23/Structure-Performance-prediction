import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, WhiteKernel, ConstantKernel
from sklearn.model_selection import cross_val_score, LeaveOneOut
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler
import pandas as pd
from scipy.stats import pearsonr
from scipy.interpolate import interp1d
import os
import glob
import warnings
warnings.filterwarnings('ignore')

# Set style for better plots
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

class N2AdsorptionGPR:
    def __init__(self, length_scale_bounds=None):
        """
        Initialize the GPR analyzer for N2 adsorption isotherms
        
        Parameters:
        length_scale_bounds: tuple or None
            If tuple, should be (min_length_scale, max_length_scale) to constrain GPR lengthscales
            If None, uses default bounds (1e-2, 1e2)
        """
        self.scaler_X = StandardScaler()
        self.scaler_y = StandardScaler()
        self.gpr_co2_uptake = None
        self.gpr_kinetic = None
        self.X_train = None
        self.y_train = None
        self.sample_names = None
        self.df = None
        self.X = None
        self.y_uptake = None
        self.y_kinetic = None
        self.feature_names = None
        self.target_names = ['CO2_uptake_qe', 'kinetic_constant_k']
        
        # Set lengthscale bounds
        if length_scale_bounds is not None:
            self.length_scale_bounds = length_scale_bounds
        else:
            self.length_scale_bounds = (1e-2, 1e2)  # Default bounds
        
    def set_lengthscale_bounds(self, min_length, max_length):
        """
        Manually set the lengthscale bounds for GPR optimization
        
        Parameters:
        min_length: minimum lengthscale value
        max_length: maximum lengthscale value
        """
        self.length_scale_bounds = (min_length, max_length)
        print(f"Lengthscale bounds set to: {self.length_scale_bounds}")
        
    def extract_isotherm_features(self, rel_pressure, n2_uptake, bet_area, co2_uptake, kinetic_constant):
        """
        Extract features from N2 adsorption isotherms
        
        Parameters:
        rel_pressure: array of relative pressure values (0 to 1)
        n2_uptake: array of N2 uptake values (mmol/g)
        bet_area: BET surface area
        co2_uptake: CO2 uptake value (mmol/g)
        kinetic_constant: kinetic constant value (1/s)
        
        Returns:
        dict of extracted features and targets
        """
        # Sort data by relative pressure
        sorted_indices = np.argsort(rel_pressure)
        rel_pressure_sorted = rel_pressure[sorted_indices]
        n2_uptake_sorted = n2_uptake[sorted_indices]
        
        # Remove duplicates and ensure monotonic pressure
        unique_indices = np.unique(rel_pressure_sorted, return_index=True)[1]
        rel_pressure_unique = rel_pressure_sorted[unique_indices]
        n2_uptake_unique = n2_uptake_sorted[unique_indices]
        
        features = {}
        
        # Basic features
        features['bet_area'] = bet_area
        features['total_n2_uptake'] = np.max(n2_uptake_unique)  # Total N2 uptake (last value)
        features['min_rel_pressure'] = np.min(rel_pressure_unique)
        features['max_rel_pressure'] = np.max(rel_pressure_unique)
        
        # Targets
        features['co2_uptake'] = co2_uptake
        features['kinetic_constant'] = kinetic_constant
        
        # Interpolation for feature extraction at specific relative pressures
        if len(rel_pressure_unique) > 1 and features['total_n2_uptake'] > 0:
            # Create interpolation function
            f_interp = interp1d(rel_pressure_unique, n2_uptake_unique, kind='linear', 
                              bounds_error=False, fill_value='extrapolate')
            
            # Extract uptake at specific relative pressures
            target_rel_pressures = [0.1, 0.25, 0.5, 0.75]
            
            # Uptake at first value (normalized)
            first_uptake = n2_uptake_unique[0]
            features['uptake_first_norm'] = first_uptake / features['total_n2_uptake']
            
            # Uptake at last value (should be 1.0 when normalized)
            last_uptake = n2_uptake_unique[-1]
            features['uptake_last_norm'] = last_uptake / features['total_n2_uptake']
            
            # Uptake at specific relative pressures (normalized)
            for p_rel in target_rel_pressures:
                if p_rel <= features['max_rel_pressure'] and p_rel >= features['min_rel_pressure']:
                    uptake_at_p = f_interp(p_rel)
                    features[f'uptake_at_{p_rel}_norm'] = uptake_at_p / features['total_n2_uptake']
                else:
                    # Extrapolate if needed
                    uptake_at_p = f_interp(p_rel)
                    features[f'uptake_at_{p_rel}_norm'] = max(0, uptake_at_p / features['total_n2_uptake'])
            
            # Additional useful features
            # Slope in low pressure region (0 to 0.1)
            if features['max_rel_pressure'] > 0.05:
                p_start = max(0, features['min_rel_pressure'])
                p_end = min(0.1, features['max_rel_pressure'])
                if p_end > p_start:
                    uptake_start = f_interp(p_start)
                    uptake_end = f_interp(p_end)
                    features['initial_slope'] = (uptake_end - uptake_start) / (p_end - p_start)
                else:
                    features['initial_slope'] = 0
            else:
                features['initial_slope'] = 0
            
            # Slope in high pressure region (0.8 to 1.0)
            if features['max_rel_pressure'] > 0.8:
                p_start = max(0.8, features['min_rel_pressure'])
                p_end = min(1.0, features['max_rel_pressure'])
                if p_end > p_start:
                    uptake_start = f_interp(p_start)
                    uptake_end = f_interp(p_end)
                    features['final_slope'] = (uptake_end - uptake_start) / (p_end - p_start)
                else:
                    features['final_slope'] = 0
            else:
                features['final_slope'] = 0
                
        else:
            # Single point or invalid data - fill with default values
            features['uptake_first_norm'] = 0
            features['uptake_last_norm'] = 1.0
            for p_rel in [0.1, 0.25, 0.5, 0.75]:
                features[f'uptake_at_{p_rel}_norm'] = 0
            features['initial_slope'] = 0
            features['final_slope'] = 0
        
        return features
    
    def load_isotherm_data(self, data_folder_path):
        """
        Load N2 adsorption isotherm data from CSV files
        
        Parameters:
        data_folder_path: path to folder containing CSV files
        
        Expected CSV format:
        Column 1: Relative Pressure (p/p°) - values from 0 to 1
        Column 2: Quantity Adsorbed (mmol/g) - N2 uptake at 77 K
        Column 3: BET area - single value (repeated in all rows)
        Column 4: qe (mmol/g) - CO2 uptake (single value)
        Column 5: k (1/s) - kinetic constant (single value)
        
        Returns:
        success: boolean indicating if data was loaded successfully
        """
        try:
            # Find all CSV files in the data folder
            csv_files = glob.glob(os.path.join(data_folder_path, "*.csv"))
            
            if not csv_files:
                print(f"No CSV files found in {data_folder_path}")
                return False
            
            print(f"Found {len(csv_files)} CSV files")
            
            all_features = []
            sample_names = []
            
            for csv_file in csv_files:
                try:
                    # Extract sample name from filename
                    sample_name = os.path.splitext(os.path.basename(csv_file))[0]
                    
                    # Load CSV file
                    df = pd.read_csv(csv_file)
                    
                    # Check if we have the expected columns
                    if df.shape[1] < 5:
                        print(f"Warning: {csv_file} has insufficient columns ({df.shape[1]}). Expected 5 columns. Skipping.")
                        continue
                    
                    # Extract data
                    rel_pressure = df.iloc[:, 0].values     # Column 1: Relative Pressure
                    n2_uptake = df.iloc[:, 1].values        # Column 2: N2 Quantity Adsorbed
                    bet_area = df.iloc[0, 2]                # Column 3: BET area (first row)
                    co2_uptake = df.iloc[0, 3]              # Column 4: CO2 uptake qe
                    kinetic_constant = df.iloc[0, 4]        # Column 5: kinetic constant k
                    
                    # Convert to numeric
                    rel_pressure = pd.to_numeric(rel_pressure, errors='coerce')
                    n2_uptake = pd.to_numeric(n2_uptake, errors='coerce')
                    bet_area = pd.to_numeric(bet_area, errors='coerce')
                    co2_uptake = pd.to_numeric(co2_uptake, errors='coerce')
                    kinetic_constant = pd.to_numeric(kinetic_constant, errors='coerce')
                    
                    # Remove NaN values from isotherm data
                    valid_mask = ~(pd.isna(rel_pressure) | pd.isna(n2_uptake))
                    rel_pressure = rel_pressure[valid_mask]
                    n2_uptake = n2_uptake[valid_mask]
                    
                    # Check for valid data
                    if (len(rel_pressure) < 2 or pd.isna(bet_area) or 
                        pd.isna(co2_uptake) or pd.isna(kinetic_constant)):
                        print(f"Warning: {csv_file} has insufficient valid data. Skipping.")
                        continue
                    
                    # Check relative pressure range (should be 0 to 1)
                    if rel_pressure.max() > 1.5 or rel_pressure.min() < -0.1:
                        print(f"Warning: {csv_file} has unusual relative pressure range "
                              f"({rel_pressure.min():.3f} to {rel_pressure.max():.3f}). "
                              f"Expected 0 to 1.")
                    
                    # Extract features
                    features = self.extract_isotherm_features(
                        rel_pressure, n2_uptake, bet_area, co2_uptake, kinetic_constant
                    )
                    
                    all_features.append(features)
                    sample_names.append(sample_name)
                    
                    print(f"Processed {sample_name}: {len(rel_pressure)} isotherm points, "
                          f"BET area: {bet_area:.1f}, CO2 uptake: {co2_uptake:.3f}, "
                          f"k: {kinetic_constant:.6f}")
                    
                except Exception as e:
                    print(f"Error processing {csv_file}: {e}")
                    continue
            
            if not all_features:
                print("No valid data could be loaded from any files.")
                return False
            
            # Convert to DataFrame
            self.df = pd.DataFrame(all_features)
            self.sample_names = np.array(sample_names)
            
            # Handle any remaining NaN values
            numeric_columns = self.df.select_dtypes(include=[np.number]).columns
            for col in numeric_columns:
                if self.df[col].isna().any():
                    if 'norm' in col:
                        # For normalized uptake values, fill with 0
                        self.df[col] = self.df[col].fillna(0)
                    else:
                        # For other features, fill with median
                        self.df[col] = self.df[col].fillna(self.df[col].median())
            
            print(f"\nSuccessfully loaded data from {len(self.df)} samples")
            print(f"Features extracted: {[col for col in self.df.columns if col not in self.target_names]}")
            print(f"Targets: {self.target_names}")
            print(f"Data shape: {self.df.shape}")
            
            return True
            
        except Exception as e:
            print(f"Error loading isotherm data: {e}")
            return False
    
    def prepare_features_and_targets(self):
        """
        Prepare feature matrix and target variables
        """
        if self.df is None:
            print("No data loaded. Please load isotherm data first.")
            return False
        
        # Feature columns (exclude target columns)
        feature_columns = [col for col in self.df.columns if col not in self.target_names]
        self.feature_names = feature_columns
        
        # Prepare feature matrix
        self.X = self.df[feature_columns].values
        
        # Prepare target variables
        self.y_uptake = self.df['co2_uptake'].values
        self.y_kinetic = self.df['kinetic_constant'].values
        
        print(f"Feature matrix shape: {self.X.shape}")
        print(f"Features: {self.feature_names}")
        print(f"Targets: {self.target_names}")
        print(f"CO2 uptake range: {self.y_uptake.min():.3f} to {self.y_uptake.max():.3f}")
        print(f"Kinetic constant range: {self.y_kinetic.min():.6f} to {self.y_kinetic.max():.6f}")
        
        return True
        
    def explore_data(self):
        """Create comprehensive data exploration plots"""
        if self.df is None:
            print("No data loaded. Please load isotherm data first.")
            return
            
        # Select numeric columns for correlation analysis
        numeric_columns = self.df.select_dtypes(include=[np.number]).columns
        
        fig, axes = plt.subplots(2, 3, figsize=(20, 12))
        
        # Correlation matrix
        corr_matrix = self.df[numeric_columns].corr()
        sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0, 
                   ax=axes[0,0], fmt='.2f')
        axes[0,0].set_title('Feature Correlation Matrix', fontsize=14, fontweight='bold')
        
        # Key feature distributions
        key_features = ['bet_area', 'total_n2_uptake', 'uptake_at_0.1_norm', 'initial_slope']
        for i, feature in enumerate(key_features):
            if feature in self.df.columns and i < 4:
                row = i // 2
                col = (i % 2) + 1
                if row < 2 and col < 3:
                    self.df[feature].hist(bins=10, alpha=0.7, ax=axes[row, col])
                    axes[row, col].set_title(f'{feature} Distribution', fontsize=12, fontweight='bold')
                    axes[row, col].set_xlabel(feature)
                    axes[row, col].set_ylabel('Frequency')
                    axes[row, col].grid(True, alpha=0.3)
        
        # Target distributions
        axes[1,2].hist(self.df['co2_uptake'], bins=10, alpha=0.7, label='CO2 Uptake', color='blue')
        axes[1,2].set_title('Target Variables Distribution', fontweight='bold')
        axes[1,2].set_xlabel('CO2 Uptake (mmol/g)')
        axes[1,2].set_ylabel('Frequency')
        axes[1,2].grid(True, alpha=0.3)
        
        # Add kinetic constant on secondary y-axis
        ax2 = axes[1,2].twinx()
        axes[1,2].hist(self.df['kinetic_constant'], bins=10, alpha=0.5, label='Kinetic Constant', color='red')
        ax2.set_ylabel('Kinetic Constant (1/s)', color='red')
        
        plt.tight_layout()
        plt.show()
        
        # Display sample statistics
        print("\n=== SAMPLE STATISTICS ===")
        print(f"Number of samples: {len(self.df)}")
        print(f"Number of features: {len(self.feature_names)}")
        print("\nKey feature statistics:")
        key_stats_cols = ['bet_area', 'total_n2_uptake', 'co2_uptake', 'kinetic_constant']
        available_cols = [col for col in key_stats_cols if col in self.df.columns]
        if available_cols:
            key_stats = self.df[available_cols].describe()
            print(key_stats)
        
        # Feature importance (correlation with targets)
        print(f"\nFeature correlation with CO2 uptake:")
        feature_cols = [col for col in self.df.columns if col not in self.target_names]
        co2_corr = self.df[feature_cols].corrwith(self.df['co2_uptake']).abs().sort_values(ascending=False)
        for i, (feature, corr) in enumerate(co2_corr.head(5).items()):
            print(f"  {i+1}. {feature}: {corr:.3f}")
    
    def train_models(self):
        """Train GPR models for both targets with configurable lengthscale constraints"""
        if self.X is None:
            print("Features not prepared. Please run prepare_features_and_targets() first.")
            return False
        
        # Scale the features
        X_scaled = self.scaler_X.fit_transform(self.X)
        
        print(f"Using lengthscale bounds: {self.length_scale_bounds}")
        
        # Define kernels with configurable lengthscale bounds
        kernel_co2 = (ConstantKernel(1.0, constant_value_bounds=(1e-3, 1e3)) * 
                      RBF(length_scale=1.0, length_scale_bounds=self.length_scale_bounds) + 
                      WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-5, 1e1)))
        
        kernel_kinetic = (ConstantKernel(1.0, constant_value_bounds=(1e-3, 1e3)) * 
                         RBF(length_scale=1.0, length_scale_bounds=self.length_scale_bounds) + 
                         WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-5, 1e1)))
        
        # Initialize and train GPR models
        self.gpr_co2_uptake = GaussianProcessRegressor(
            kernel=kernel_co2, 
            alpha=1e-6, 
            normalize_y=True,
            n_restarts_optimizer=10
        )
        
        self.gpr_kinetic = GaussianProcessRegressor(
            kernel=kernel_kinetic, 
            alpha=1e-6, 
            normalize_y=True,
            n_restarts_optimizer=10
        )
        
        # Fit models
        self.gpr_co2_uptake.fit(X_scaled, self.y_uptake)
        self.gpr_kinetic.fit(X_scaled, self.y_kinetic)
        
        print("Models trained successfully!")
        print(f"CO2 Uptake model kernel: {self.gpr_co2_uptake.kernel_}")
        print(f"Kinetic Constant model kernel: {self.gpr_kinetic.kernel_}")
        
        return True
        
    def cross_validate(self):
        """Perform cross-validation"""
        if self.gpr_co2_uptake is None or self.gpr_kinetic is None:
            print("Models not trained. Please run train_models() first.")
            return None, None
        
        X_scaled = self.scaler_X.transform(self.X)
        
        # Leave-One-Out CV for small dataset
        loo = LeaveOneOut()
        
        # CV scores for CO2 uptake
        cv_scores_co2 = cross_val_score(self.gpr_co2_uptake, X_scaled, self.y_uptake, 
                                           cv=loo, scoring='r2')
        
        # CV scores for kinetic constant
        cv_scores_kinetic = cross_val_score(self.gpr_kinetic, X_scaled, self.y_kinetic, 
                                           cv=loo, scoring='r2')
        
        print(f"\nCross-Validation Results (Leave-One-Out):")
        print(f"CO2 Uptake - Mean R²: {cv_scores_co2.mean():.3f} ± {cv_scores_co2.std():.3f}")
        print(f"Kinetic Constant - Mean R²: {cv_scores_kinetic.mean():.3f} ± {cv_scores_kinetic.std():.3f}")
        
        return cv_scores_co2, cv_scores_kinetic
    
    def plot_predictions(self):
        """Plot actual vs predicted values with uncertainty"""
        if self.gpr_co2_uptake is None or self.gpr_kinetic is None:
            print("Models not trained. Please run train_models() first.")
            return None, None, None, None
        
        X_scaled = self.scaler_X.transform(self.X)
        
        # Predictions with uncertainty
        y_pred_co2, y_std_co2 = self.gpr_co2_uptake.predict(X_scaled, return_std=True)
        y_pred_kinetic, y_std_kinetic = self.gpr_kinetic.predict(X_scaled, return_std=True)
        
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))
        
        # CO2 Uptake predictions
        axes[0].scatter(self.y_uptake, y_pred_co2, alpha=0.7, s=60)
        axes[0].errorbar(self.y_uptake, y_pred_co2, yerr=y_std_co2, 
                        fmt='none', alpha=0.5, capsize=3)

        # Perfect prediction line
        min_val = min(self.y_uptake.min(), y_pred_co2.min())
        max_val = max(self.y_uptake.max(), y_pred_co2.max())
        axes[0].plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8, linewidth=2)
        
        r2_co2 = r2_score(self.y_uptake, y_pred_co2)
        rmse_co2 = np.sqrt(mean_squared_error(self.y_uptake, y_pred_co2))
        axes[0].set_title(f'CO2 Uptake Predictions\nR² = {r2_co2:.3f}, RMSE = {rmse_co2:.3f}', 
                         fontweight='bold')
        axes[0].set_xlabel('Actual CO2 Uptake (mmol/g)')
        axes[0].set_ylabel('Predicted CO2 Uptake (mmol/g)')
        axes[0].grid(True, alpha=0.3)
        
        # Kinetic Constant predictions
        axes[1].scatter(self.y_kinetic, y_pred_kinetic, alpha=0.7, s=60)
        axes[1].errorbar(self.y_kinetic, y_pred_kinetic, yerr=y_std_kinetic, 
                        fmt='none', alpha=0.5, capsize=3)
        
        # Perfect prediction line
        min_val = min(self.y_kinetic.min(), y_pred_kinetic.min())
        max_val = max(self.y_kinetic.max(), y_pred_kinetic.max())
        axes[1].plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8, linewidth=2)
        
        r2_kinetic = r2_score(self.y_kinetic, y_pred_kinetic)
        rmse_kinetic = np.sqrt(mean_squared_error(self.y_kinetic, y_pred_kinetic))
        axes[1].set_title(f'Kinetic Constant Predictions\nR² = {r2_kinetic:.3f}, RMSE = {rmse_kinetic:.6f}', 
                         fontweight='bold')
        axes[1].set_xlabel('Actual Kinetic Constant (1/s)')
        axes[1].set_ylabel('Predicted Kinetic Constant (1/s)')
        axes[1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        return r2_co2, rmse_co2, r2_kinetic, rmse_kinetic
    
    def plot_response_surfaces(self):
        """Plot 2D response surfaces for key feature pairs"""
        # Select two most important features for surface plots
        if len(self.feature_names) < 2:
            print("Need at least 2 features for response surface plots")
            return
            
        # Use BET area and total_uptake if available, otherwise first two features
        feature1_name = 'bet_area' if 'bet_area' in self.feature_names else self.feature_names[0]
        feature2_name = 'total_uptake' if 'total_uptake' in self.feature_names else self.feature_names[1]
        
        feature1_idx = self.feature_names.index(feature1_name)
        feature2_idx = self.feature_names.index(feature2_name)
        
        # Create grid for surface plots
        f1_range = np.linspace(self.X[:, feature1_idx].min(), self.X[:, feature1_idx].max(), 50)
        f2_range = np.linspace(self.X[:, feature2_idx].min(), self.X[:, feature2_idx].max(), 50)
        F1_grid, F2_grid = np.meshgrid(f1_range, f2_range)
        
        # Create grid points with mean values for other features
        grid_points = np.zeros((F1_grid.size, len(self.feature_names)))
        for i, feature_name in enumerate(self.feature_names):
            if i == feature1_idx:
                grid_points[:, i] = F1_grid.ravel()
            elif i == feature2_idx:
                grid_points[:, i] = F2_grid.ravel()
            else:
                grid_points[:, i] = np.mean(self.X[:, i])
        
        grid_scaled = self.scaler_X.transform(grid_points)
        
        # Predictions
        uptake_pred, uptake_std = self.gpr_co2_uptake.predict(grid_scaled, return_std=True)
        kinetic_pred, kinetic_std = self.gpr_kinetic.predict(grid_scaled, return_std=True)
        
        # Reshape for contour plots
        uptake_surface = uptake_pred.reshape(F1_grid.shape)
        kinetic_surface = kinetic_pred.reshape(F1_grid.shape)
        uptake_uncertainty = uptake_std.reshape(F1_grid.shape)
        kinetic_uncertainty = kinetic_std.reshape(F1_grid.shape)
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # CO2 Uptake surface
        cs1 = axes[0,0].contourf(F1_grid, F2_grid, uptake_surface, levels=20, cmap='viridis')
        axes[0,0].scatter(self.X[:, feature1_idx], self.X[:, feature2_idx], 
                         c=self.y_uptake, s=60, cmap='viridis', edgecolors='white')
        axes[0,0].set_title('CO2 Uptake Response Surface', fontweight='bold')
        axes[0,0].set_xlabel(feature1_name)
        axes[0,0].set_ylabel(feature2_name)
        plt.colorbar(cs1, ax=axes[0,0], label='CO2 Uptake (mmol/g)')
        
        # CO2 Uptake uncertainty
        cs2 = axes[0,1].contourf(F1_grid, F2_grid, uptake_uncertainty, levels=20, cmap='Reds')
        axes[0,1].scatter(self.X[:, feature1_idx], self.X[:, feature2_idx], 
                         c='white', s=60, edgecolors='black')
        axes[0,1].set_title('CO2 Uptake Prediction Uncertainty', fontweight='bold')
        axes[0,1].set_xlabel(feature1_name)
        axes[0,1].set_ylabel(feature2_name)
        plt.colorbar(cs2, ax=axes[0,1], label='Standard Deviation')
        
        # Kinetic Constant surface
        cs3 = axes[1,0].contourf(F1_grid, F2_grid, kinetic_surface, levels=20, cmap='plasma')
        axes[1,0].scatter(self.X[:, feature1_idx], self.X[:, feature2_idx], 
                         c=self.y_kinetic, s=60, cmap='plasma', edgecolors='white')
        axes[1,0].set_title('Kinetic Constant Response Surface', fontweight='bold')
        axes[1,0].set_xlabel(feature1_name)
        axes[1,0].set_ylabel(feature2_name)
        plt.colorbar(cs3, ax=axes[1,0], label='Kinetic Constant (1/s)')
        
        # Kinetic Constant uncertainty
        cs4 = axes[1,1].contourf(F1_grid, F2_grid, kinetic_uncertainty, levels=20, cmap='Reds')
        axes[1,1].scatter(self.X[:, feature1_idx], self.X[:, feature2_idx], 
                         c='white', s=60, edgecolors='black')
        axes[1,1].set_title('Kinetic Constant Prediction Uncertainty', fontweight='bold')
        axes[1,1].set_xlabel(feature1_name)
        axes[1,1].set_ylabel(feature2_name)
        plt.colorbar(cs4, ax=axes[1,1], label='Standard Deviation')
        
        plt.tight_layout()
        plt.show()
    
    def set_lengthscale_bounds(self, bounds):
        """
        Set custom lengthscale bounds for GPR kernels
        
        Parameters:
        bounds: tuple (min_bound, max_bound) for lengthscale constraints
        """
        self.length_scale_bounds = bounds
        print(f"Lengthscale bounds set to: {bounds}")
        
        # If models are already trained, retrain with new bounds
        if self.gpr_co2_uptake is not None:
            print("Retraining models with new lengthscale bounds...")
            self.train_models()
    
    def predict_new_sample(self, feature_dict):
        """
        Predict CO2 uptake and kinetic constant for new samples
        
        Parameters:
        feature_dict: dictionary with feature names as keys and values as values
        """
        # Create feature vector
        X_new = np.zeros((1, len(self.feature_names)))
        for i, feature_name in enumerate(self.feature_names):
            if feature_name in feature_dict:
                X_new[0, i] = feature_dict[feature_name]
            else:
                # Use mean value for missing features
                X_new[0, i] = np.mean(self.X[:, i])
                print(f"Warning: {feature_name} not provided, using mean value: {X_new[0, i]:.3f}")
        
        X_new_scaled = self.scaler_X.transform(X_new)
        
        uptake_pred, uptake_std = self.gpr_co2_uptake.predict(X_new_scaled, return_std=True)
        kinetic_pred, kinetic_std = self.gpr_kinetic.predict(X_new_scaled, return_std=True)     
        
        print(f"\nPrediction for new sample:")
        for feature_name, value in feature_dict.items():
            print(f"  {feature_name}: {value}")
        print(f"CO2 Uptake: {uptake_pred[0]:.3f} ± {uptake_std[0]:.3f} mmol/g")
        print(f"Kinetic Constant: {kinetic_pred[0]:.4f} ± {kinetic_std[0]:.4f} 1/s")
        
        return uptake_pred[0], uptake_std[0], kinetic_pred[0], kinetic_std[0]
    
    def extract_isotherm_features(self, rel_pressure, n2_uptake, bet_area):
        """
        Extract features from nitrogen adsorption isotherms
        
        Parameters:
        rel_pressure: array of relative pressure values (0-1)
        n2_uptake: array of N2 uptake values (mmol/g)
        bet_area: BET surface area
        
        Returns:
        dict of extracted features
        """
        # Sort data by relative pressure
        sorted_indices = np.argsort(rel_pressure)
        rel_pressure_sorted = rel_pressure[sorted_indices]
        n2_uptake_sorted = n2_uptake[sorted_indices]
        
        # Remove duplicates
        unique_indices = np.unique(rel_pressure_sorted, return_index=True)[1]
        rel_pressure_unique = rel_pressure_sorted[unique_indices]
        n2_uptake_unique = n2_uptake_sorted[unique_indices]
        
        features = {}
        
        # BET area
        features['bet_area'] = bet_area
        
        # Total uptake (last value)
        features['total_uptake'] = n2_uptake_unique[-1]
        
        # Uptake at specific relative pressures
        target_rel_pressures = [0.1, 0.25, 0.5, 0.75]
        
        if len(rel_pressure_unique) > 1:
            # Create interpolation function
            f_interp = interp1d(rel_pressure_unique, n2_uptake_unique, kind='linear', 
                              bounds_error=False, fill_value='extrapolate')
            
            # First and last uptake values (normalized by total uptake)
            features['uptake_first_norm'] = n2_uptake_unique[0] / features['total_uptake'] if features['total_uptake'] > 0 else 0
            features['uptake_last_norm'] = 1.0  # Last value normalized by itself is always 1
            
            # Uptake at target relative pressures (normalized)
            for p in target_rel_pressures:
                if p <= rel_pressure_unique[-1] and p >= rel_pressure_unique[0]:
                    uptake_at_p = f_interp(p)
                    features[f'uptake_at_{p}_norm'] = uptake_at_p / features['total_uptake'] if features['total_uptake'] > 0 else 0
                else:
                    features[f'uptake_at_{p}_norm'] = np.nan
        else:
            # Single point data
            features['uptake_first_norm'] = 1.0 if features['total_uptake'] > 0 else 0
            features['uptake_last_norm'] = 1.0
            for p in target_rel_pressures:
                features[f'uptake_at_{p}_norm'] = np.nan
        
        return features
    
    def load_isotherm_data(self, data_folder_path):
        """
        Load nitrogen adsorption isotherm data and CO2 uptake/kinetic data from CSV files
        
        Parameters:
        data_folder_path: path to folder containing CSV files
        
        Expected CSV format:
        Column 1: Relative Pressure (p/p°) (0-1)
        Column 2: Quantity Adsorbed (mmol/g) - N2 at 77K
        Column 3: BET area (single value)
        Column 4: CO2 uptake qe (mmol/g) (single value)
        Column 5: Kinetic constant k (1/s) (single value)
        
        Returns:
        success: boolean indicating if data was loaded successfully
        """
        try:
            # Find all CSV files in the data folder
            csv_files = glob.glob(os.path.join(data_folder_path, "*.csv"))
            
            if not csv_files:
                print(f"No CSV files found in {data_folder_path}")
                return False
            
            print(f"Found {len(csv_files)} CSV files")
            
            all_features = []
            sample_names = []
            co2_uptakes = []
            kinetic_constants = []
            
            for csv_file in csv_files:
                try:
                    # Extract sample name from filename
                    sample_name = os.path.splitext(os.path.basename(csv_file))[0]
                    
                    # Load CSV file
                    df = pd.read_csv(csv_file)
                    
                    # Check if we have the expected columns
                    if df.shape[1] < 5:
                        print(f"Warning: {csv_file} has insufficient columns. Expected 5, got {df.shape[1]}. Skipping.")
                        continue
                    
                    # Extract data
                    rel_pressure = df.iloc[:, 0].values      # Relative pressure
                    n2_uptake = df.iloc[:, 1].values         # N2 uptake
                    bet_area = df.iloc[0, 2]                 # BET area (single value)
                    co2_uptake = df.iloc[0, 3]               # CO2 uptake (single value)
                    kinetic_constant = df.iloc[0, 4]         # Kinetic constant (single value)
                    
                    # Convert to numeric
                    rel_pressure = pd.to_numeric(rel_pressure, errors='coerce')
                    n2_uptake = pd.to_numeric(n2_uptake, errors='coerce')
                    bet_area = pd.to_numeric(bet_area, errors='coerce')
                    co2_uptake = pd.to_numeric(co2_uptake, errors='coerce')
                    kinetic_constant = pd.to_numeric(kinetic_constant, errors='coerce')
                    
                    # Remove NaN values from isotherm data
                    valid_mask = ~(pd.isna(rel_pressure) | pd.isna(n2_uptake))
                    rel_pressure = rel_pressure[valid_mask]
                    n2_uptake = n2_uptake[valid_mask]
                    
                    # Check data validity
                    if (len(rel_pressure) < 2 or pd.isna(bet_area) or 
                        pd.isna(co2_uptake) or pd.isna(kinetic_constant)):
                        print(f"Warning: {csv_file} has insufficient valid data. Skipping.")
                        continue
                    
                    # Extract features from isotherm
                    features = self.extract_isotherm_features(rel_pressure, n2_uptake, bet_area)
                    
                    all_features.append(features)
                    sample_names.append(sample_name)
                    co2_uptakes.append(co2_uptake)
                    kinetic_constants.append(kinetic_constant)
                    
                    print(f"Processed {sample_name}: {len(rel_pressure)} isotherm points, "
                          f"BET: {bet_area:.1f}, CO2 uptake: {co2_uptake:.3f}, k: {kinetic_constant:.4f}")
                    
                except Exception as e:
                    print(f"Error processing {csv_file}: {e}")
                    continue
            
            if not all_features:
                print("No valid data could be loaded from any files.")
                return False
            
            # Convert to DataFrame
            self.df = pd.DataFrame(all_features)
            self.sample_names = np.array(sample_names)
            
            # Add target variables to DataFrame
            self.df['co2_uptake'] = co2_uptakes
            self.df['kinetic_constant'] = kinetic_constants
            
            # Handle NaN values in features
            numeric_columns = self.df.select_dtypes(include=[np.number]).columns
            for col in numeric_columns:
                if col not in ['co2_uptake', 'kinetic_constant'] and self.df[col].isna().any():
                    if 'norm' in col:
                        # For normalized uptake values, fill with median
                        self.df[col] = self.df[col].fillna(self.df[col].median())
                    else:
                        # For other features, fill with median
                        self.df[col] = self.df[col].fillna(self.df[col].median())
            
            print(f"\nSuccessfully loaded data from {len(self.df)} samples")
            print(f"Features extracted: {[col for col in self.df.columns if col not in ['co2_uptake', 'kinetic_constant']]}")
            print(f"Target variables: CO2 uptake, Kinetic constant")
            print(f"Data shape: {self.df.shape}")
            
            return True
            
        except Exception as e:
            print(f"Error loading isotherm data: {e}")
            return False
    
    def prepare_features_and_targets(self):
        """
        Prepare feature matrix and target variables for CO2 uptake and kinetic constant
        """
        # Feature columns (exclude target variables)
        feature_columns = [col for col in self.df.columns if col not in ['co2_uptake', 'kinetic_constant']]
        
        # Prepare feature matrix
        self.X = self.df[feature_columns].values
        
        # Prepare target variables
        self.y_uptake = self.df['co2_uptake'].values
        self.y_kinetic = self.df['kinetic_constant'].values
        
        self.feature_names = feature_columns
        self.target_names = ['co2_uptake', 'kinetic_constant']
        
        print(f"Feature matrix shape: {self.X.shape}")
        print(f"Features: {self.feature_names}")
        print(f"Targets: {self.target_names}")
        print(f"CO2 uptake range: {self.y_uptake.min():.3f} - {self.y_uptake.max():.3f} mmol/g")
        print(f"Kinetic constant range: {self.y_kinetic.min():.4f} - {self.y_kinetic.max():.4f} 1/s")


if __name__ == "__main__":
    print("=== CO2 Uptake Gaussian Process Regression Analysis ===\n")
    
    # Initialize the GPR analyzer
    # Option 1: Use default lengthscale bounds
    analyzer = N2AdsorptionGPR()
    
    # Option 2: Use custom lengthscale bounds (uncomment to use)
    # analyzer = CO2UptakeGPR(length_scale_bounds=(0.1, 10.0))
    
    # Step 1: Load nitrogen adsorption isotherm data with CO2 uptake targets
    print("Step 1: Loading nitrogen adsorption isotherm data...")
    data_folder = "Isotherm_Uptake_Prediction/BET_Isotherms"  # Replace with your actual data folder path
    
    success = analyzer.load_isotherm_data(data_folder)
    
    if not success:
        print("Failed to load data. Please check your data folder and CSV files.")
        print("\nExpected CSV format:")
        print("Column 1: Relative Pressure (p/p°) (0-1)")
        print("Column 2: Quantity Adsorbed (mmol/g) - N2 at 77K")
        print("Column 3: BET area (single value)")
        print("Column 4: CO2 uptake qe (mmol/g) (single value)")
        print("Column 5: Kinetic constant k (1/s) (single value)")
        exit(1)
    
    # Step 2: Prepare features and targets
    print("\nStep 2: Preparing features and target variables...")
    analyzer.prepare_features_and_targets()
    
    # Step 3: Data exploration
    print("\nStep 3: Exploring the data...")
    analyzer.explore_data()
    
    # Step 4: Train the GPR models
    print("\nStep 4: Training Gaussian Process Regression models...")
    analyzer.train_models()
    
    # Optional: Manually adjust lengthscale bounds
    print("\nOptional: Adjust lengthscale bounds manually")
    adjust_bounds = input("Would you like to adjust lengthscale bounds? (y/n): ").lower().strip()
    if adjust_bounds == 'y':
        try:
            min_bound = float(input("Enter minimum lengthscale bound (e.g., 0.1): "))
            max_bound = float(input("Enter maximum lengthscale bound (e.g., 10.0): "))
            analyzer.set_lengthscale_bounds((min_bound, max_bound))
        except ValueError:
            print("Invalid input, using default bounds")
    
    # Step 5: Cross-validation
    print("\nStep 5: Performing cross-validation...")
    cv_scores_uptake, cv_scores_kinetic = analyzer.cross_validate()
    
    # Step 6: Plot predictions vs actual values
    print("\nStep 6: Plotting predictions...")
    r2_uptake, rmse_uptake, r2_kinetic, rmse_kinetic = analyzer.plot_predictions()
    
    # Step 7: Plot response surfaces
    print("\nStep 7: Creating response surface plots...")
    analyzer.plot_response_surfaces()
    
    # Step 8: Demonstrate prediction for new samples
    print("\nStep 8: Predicting CO2 uptake and kinetic constant for new samples...")
    
    # Example prediction with key features
    print("\n--- Example prediction ---")
    example_features = {
        'bet_area': 500.0,
        'total_uptake': 15.0,
        'uptake_at_0.1_norm': 0.3,
        'uptake_at_0.5_norm': 0.7
    }
    
    analyzer.predict_new_sample(example_features)
    
    # Step 9: Model performance summary
    print("\n" + "="*60)
    print("FINAL MODEL PERFORMANCE SUMMARY")
    print("="*60)
    
    print(f"\nDataset Information:")
    print(f"  Number of samples: {len(analyzer.df)}")
    print(f"  Number of features: {len(analyzer.feature_names)}")
    print(f"  Sample names: {', '.join(analyzer.sample_names[:5])}{'...' if len(analyzer.sample_names) > 5 else ''}")
    
    print(f"\nModel Performance (Training Set):")
    print(f"  CO2 Uptake:")
    print(f"    R² Score: {r2_uptake:.3f}")
    print(f"    RMSE: {rmse_uptake:.3f} mmol/g")
    
    print(f"  Kinetic Constant:")
    print(f"    R² Score: {r2_kinetic:.3f}")
    print(f"    RMSE: {rmse_kinetic:.4f} 1/s")
    
    print(f"\nCross-Validation Performance (Leave-One-Out):")
    print(f"  CO2 Uptake CV R²: {cv_scores_uptake.mean():.3f} ± {cv_scores_uptake.std():.3f}")
    print(f"  Kinetic Constant CV R²: {cv_scores_kinetic.mean():.3f} ± {cv_scores_kinetic.std():.3f}")
    
    print(f"\nModel Hyperparameters:")
    print(f"  CO2 Uptake kernel: {analyzer.gpr_co2_uptake.kernel_}")
    print(f"  Kinetic Constant kernel: {analyzer.gpr_kinetic.kernel_}")
    
    print(f"\nAnalysis complete! The GPR models are trained to predict CO2 uptake and kinetic constants")
    print("from nitrogen adsorption isotherm features.")
